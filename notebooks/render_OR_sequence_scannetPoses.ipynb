{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41ffc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "val_list_file = '/home/ruizhu/Documents/Projects/semanticInverse/train/data/openrooms/list_OR_tmp/list/val.txt'\n",
    "list_read = open(val_list_file).readlines()\n",
    "scene_list = []\n",
    "for line in list_read:\n",
    "    line = line.strip()\n",
    "    line_split = line.split(' ')\n",
    "    meta_split = line_split[2].split('/')[0]\n",
    "    scene_name = line_split[2].split('/')[1]\n",
    "    scene_list.append('/'.join([meta_split, scene_name]))\n",
    "    \n",
    "scene_list = list(set(scene_list))\n",
    "\n",
    "print(len(scene_list))\n",
    "\n",
    "from pathlib import Path\n",
    "# render_dest = Path('/home/ruizhu/Documents/Projects/semanticInverse/dataset/openrooms_sequence_val')\n",
    "render_dest = Path('/home/ruizhu/Documents/Projects/semanticInverse/dataset/openrooms_sequence_val_notSkipFrames')\n",
    "xml_dest = render_dest / 'scenes'\n",
    "xml_ori = Path('/newfoundland2/ruizhu/siggraphasia20dataset/code/Routine/scenes')\n",
    "ScanNet_RAW_root = Path('/newfoundland2/ruizhu/scannet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0907eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/scene0509_00/scene0509_00.sens --output_path /newfoundland2/ruizhu/scannet/labels_2d_240x320_notSkipFrames/scene0509_00 --export_poses --export_depth_images --export_intrinsics --export_color_images\n",
      "cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/scene0403_01/scene0403_01.sens --output_path /newfoundland2/ruizhu/scannet/labels_2d_240x320_notSkipFrames/scene0403_01 --export_poses --export_depth_images --export_intrinsics --export_color_images\n",
      "cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/scene0649_00/scene0649_00.sens --output_path /newfoundland2/ruizhu/scannet/labels_2d_240x320_notSkipFrames/scene0649_00 --export_poses --export_depth_images --export_intrinsics --export_color_images\n",
      "cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/scene0552_00/scene0552_00.sens --output_path /newfoundland2/ruizhu/scannet/labels_2d_240x320_notSkipFrames/scene0552_00 --export_poses --export_depth_images --export_intrinsics --export_color_images\n",
      "cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/scene0610_01/scene0610_01.sens --output_path /newfoundland2/ruizhu/scannet/labels_2d_240x320_notSkipFrames/scene0610_01 --export_poses --export_depth_images --export_intrinsics --export_color_images\n",
      "cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/scene0701_02/scene0701_02.sens --output_path /newfoundland2/ruizhu/scannet/labels_2d_240x320_notSkipFrames/scene0701_02 --export_poses --export_depth_images --export_intrinsics --export_color_images\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shutil \n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/home/ruizhu/Documents/Projects/Total3DUnderstanding/utils_OR/DatasetCreation/')\n",
    "from sampleCameraPoseFromScanNet import computeCameraEx\n",
    "\n",
    "# scene_idx_select = scene_list.index('mainDiffLight_xml1/scene0509_00')\n",
    "# # scene_idx = 0\n",
    "# for scene_idx in range(len(scene_list)):\n",
    "#     if scene_idx != scene_idx_select:\n",
    "#         continue\n",
    "#     meta_split, scene_name = scene_list[scene_idx].split('/')\n",
    "\n",
    "# ScanNet_root = Path('/newfoundland2/ruizhu/scannet/labels_2d_240x320/')\n",
    "ScanNet_root = ScanNet_RAW_root / 'labels_2d_240x320_notSkipFrames'\n",
    "\n",
    "for line in list_read[:20]:\n",
    "    line = line.strip()\n",
    "    line_split = line.split(' ')\n",
    "    meta_split = line_split[2].split('/')[0]\n",
    "    scene_name = line_split[2].split('/')[1]\n",
    "    \n",
    "    ScanNet_scene_path = ScanNet_root / scene_name\n",
    "    if not ScanNet_scene_path.exists():\n",
    "        ScanNet_scene_path.mkdir(parents=True)\n",
    "        # dump ScanNet labels\n",
    "        cmd = 'cd /home/ruizhu/Documents/Projects/ENet-ScanNet/prepare_data && python reader.py --filename /newfoundland2/ruizhu/scannet/scans/%s/%s.sens --output_path %s --export_poses --export_depth_images --export_intrinsics --export_color_images'%\\\n",
    "            (scene_name, scene_name, str(ScanNet_scene_path))\n",
    "        print(cmd)\n",
    "        os.system(cmd)\n",
    "        \n",
    "    continue\n",
    "    \n",
    "    ScanNet_pose_path = ScanNet_root  / scene_name / 'pose'\n",
    "    render_dest_scene = render_dest / meta_split / scene_name\n",
    "#     if render_dest_scene.exists():\n",
    "#         continue\n",
    "    render_dest_scene.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # /home/ruizhu/Documents/Projects/Total3DUnderstanding/utils_OR/DatasetCreation/sampleCameraPoseFromScanNet.py\n",
    "\n",
    "    # Load transformation file\n",
    "    xml_ori_scene = xml_ori / meta_split.split('_')[1] / scene_name\n",
    "    xml_dest_scene = xml_dest / meta_split.split('_')[1] / scene_name\n",
    "#     assert xml_dest_scene.exists() == False\n",
    "    if xml_dest_scene.exists() == False:\n",
    "        shutil.copytree(str(xml_ori_scene), str(xml_dest_scene)) \n",
    "            \n",
    "    transformFile = str(xml_dest_scene / 'transform.dat')\n",
    "    with open(transformFile, 'rb') as fIn:\n",
    "        transforms = pickle.load(fIn)\n",
    "\n",
    "    # Generate cam.txt            \n",
    "    poseDir = str(ScanNet_pose_path)\n",
    "    poseNum = len(glob.glob(osp.join(poseDir, '*.txt') ) )\n",
    "    isSelected = np.zeros(poseNum, dtype=np.int32 )\n",
    "    camGap = 20\n",
    "\n",
    "    for n in range(0, poseNum, camGap ):\n",
    "        isSelected[n] = 1\n",
    "\n",
    "    camPoses= []\n",
    "    for n in range(0, 10000, camGap ):\n",
    "\n",
    "        poseFile = osp.join(poseDir, '%d.txt' % n)\n",
    "        if not osp.isfile(poseFile ):\n",
    "            print('ScanNet pose file not found at %s'%poseFile)\n",
    "            break\n",
    "\n",
    "        camMat = np.zeros((4, 4), dtype=np.float32 )\n",
    "\n",
    "        isValidCam = True\n",
    "        with open(poseFile, 'r') as camIn:\n",
    "            for n in range(0, 4):\n",
    "                camLine = camIn.readline().strip()\n",
    "                if camLine.find('inf') != -1 or camLine.find('Inf') != -1:\n",
    "                    print(camLine, poseFile)\n",
    "                    isValidCam = False\n",
    "                    break\n",
    "\n",
    "                camLine  = [float(x) for x in camLine.split(' ') ]\n",
    "                for m in range(0, 4):\n",
    "                    camMat[n, m] = camLine[m]\n",
    "\n",
    "        if isValidCam == False:\n",
    "            continue\n",
    "#             while not isValidCam:\n",
    "#                 camMat = np.zeros((4,4), dtype=np.float32 )\n",
    "#                 while True:\n",
    "#                     camId = np.random.randint(0, poseNum )\n",
    "#                     if isSelected[camId ] == 0:\n",
    "#                         break\n",
    "#                 poseFile = osp.join(poseDir, '%d.txt' % camId )\n",
    "#                 isValidCam = True\n",
    "#                 with open(poseFile, 'r') as camIn:\n",
    "#                     for n in range(0, 4):\n",
    "#                         camLine = camIn.readline().strip()\n",
    "#                         if camLine.find('inf') != -1 or camLine.find('Inf') != -1:\n",
    "#                             isValidCam = False\n",
    "#                             break\n",
    "#                         camLine  = [float(x) for x in camLine.split(' ') ]\n",
    "\n",
    "#                         for m in range(0, 4):\n",
    "#                             camMat[n, m] = camLine[m]\n",
    "\n",
    "#             rot = camMat[0:3, 0:3]\n",
    "#             trans = camMat[0:3, 3]\n",
    "\n",
    "#             origin, lookat, up = computeCameraEx(rot, trans,\n",
    "#                     transforms[0][0][1], transforms[0][1][1], transforms[0][2][1] )\n",
    "#             isSelected[camId ] = 1\n",
    "\n",
    "#             origin = origin.reshape(1, 3 )\n",
    "#             lookat = lookat.reshape(1, 3 )\n",
    "#             up = up.reshape(1, 3 )\n",
    "#             camPose = np.concatenate([origin, lookat, up ], axis=0 )\n",
    "#             camPoses.append(camPose )\n",
    "        else:\n",
    "            rot = camMat[0:3, 0:3]\n",
    "            trans = camMat[0:3, 3]\n",
    "\n",
    "            origin, lookat, up = computeCameraEx(rot, trans,\n",
    "                    transforms[0][0][1], transforms[0][1][1], transforms[0][2][1] )\n",
    "\n",
    "            origin = origin.reshape(1, 3 )\n",
    "            lookat = lookat.reshape(1, 3 )\n",
    "            up = up.reshape(1, 3 )\n",
    "            camPose = np.concatenate([origin, lookat, up ], axis=0 )\n",
    "            camPoses.append(camPose )\n",
    "\n",
    "\n",
    "    # Output the initial camera poses\n",
    "    camNum = len(camPoses )\n",
    "    xml_outDir = str(xml_dest_scene)\n",
    "    with open(osp.join(xml_outDir, 'cam.txt'), 'w') as camOut:\n",
    "        camOut.write('%d\\n' % camNum )\n",
    "        print('Final sampled camera poses: %d' % len(camPoses ) )\n",
    "        print('===> writing cam.txt to %s'%osp.join(xml_outDir, 'cam.txt'))\n",
    "        for camPose in camPoses:\n",
    "            for n in range(0, 3):\n",
    "                camOut.write('%.3f %.3f %.3f\\n' % \\\n",
    "                        (camPose[n, 0], camPose[n, 1], camPose[n, 2] ) )\n",
    "    \n",
    "                \n",
    "#     cmd = 'cd /home/ruizhu/Documents/Projects/semanticInverse/dataset/openrooms_sequence_val && CUDA_VISIBLE_DEVICES=0 python renderImg.py \\\n",
    "#     --xmlRoot /home/ruizhu/Documents/Projects/semanticInverse/dataset/openrooms_sequence_val/scenes/%s --outRoot /home/ruizhu/Documents/Projects/semanticInverse/dataset/openrooms_sequence_val/'%\\\n",
    "#     (meta_split.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd909ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a5aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:semanticInverse] *",
   "language": "python",
   "name": "conda-env-semanticInverse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5664 ['scene0509_00', '1', 'mainDiffLight_xml1/scene0509_00/im_1.hdr', 'main_xml1/scene0509_00/imsemLabel_1.npy']\n"
     ]
    }
   ],
   "source": [
    "# borrowed from Total3D repo -> notebooks/parse_OR_labels-lighting-reindexed%2Bassigned-V4.ipynb\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ruizhu/Documents/Projects/semanticInverse/train')\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "# dataset = 'sunrgbd'\n",
    "dataset = 'OR'\n",
    "\n",
    "mode = 'val'\n",
    "# mode = 'train'\n",
    "# mode = 'train-tmp'\n",
    "\n",
    "# split_path_dict = {'sunrgbd': 'data/sunrgbd/preprocessed', 'OR': 'utils_OR/openrooms/preprocessed-full'}\n",
    "split_path_dict = {'sunrgbd': 'data/sunrgbd/preprocessed', 'OR': '/home/ruizhu/Documents/Projects/semanticInverse/train/data/openrooms/list_OR_V4full/list'}\n",
    "\n",
    "if dataset == 'sunrgbd':\n",
    "    split_file = os.path.join(split_path_dict[dataset], mode + '.json')\n",
    "    with open(split_file) as file:\n",
    "        split = json.load(file)\n",
    "elif dataset == 'OR':\n",
    "    split_file = os.path.join(split_path_dict[dataset], mode + '.txt')\n",
    "    with open(split_file) as f:\n",
    "        mylist = f.read().splitlines() \n",
    "    split = [x.split(' ') for x in mylist]\n",
    "\n",
    "print(len(split), split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ruizhu/OR-V4full-detachEmitterRERERE20210425-OR45_total3D_train_test_data/mainDiffLight_xml/scene0385_01/layout_obj_32_reindexed.pkl\n",
      "dict_keys(['rgb_img_path', 'bins_tensor', 'est_data', 'gt_cam_R', 'cam_K', 'gt_layout', 'pre_layout', 'pre_cam_R', 'image'])\n",
      "dict_keys(['cells_vis_info_list', 'cell_info_grid_GT', 'cell_info_grid_PRED', 'emitter_cls_prob_PRED', 'emitter_cls_prob_GT', 'pre_layout', 'pre_cam_R', 'envmap_lightAccu_mean_vis_GT'])\n",
      "119.1801 0.1263157894736842\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from utils.utils_total3D.utils_OR_visualize import format_layout, Box\n",
    "from utils.utils_total3D.data_config import OR4XCLASSES_dict, NYU40CLASSES\n",
    "from utils.utils_total3D.utils_others import OR4X_mapping_catInt_to_RGB, OR4X_mapping_catStr_to_RGB\n",
    "from utils.utils_total3D.utils_OR_vis_labels import read_vis_scene_3d, RGB_to_01\n",
    "import pickle\n",
    "\n",
    "OR = 'OR45'\n",
    "classes = OR4XCLASSES_dict[OR] if dataset == 'OR' else NYU40CLASSES\n",
    "with open(str(Path('../train/data/openrooms/total3D_colors/') / OR4X_mapping_catInt_to_RGB['light']), 'rb') as f:\n",
    "    OR_mapping_catInt_to_RGB = pickle.load(f)[OR]\n",
    "with open(str(Path('../train/data/openrooms/total3D_colors/') / OR4X_mapping_catStr_to_RGB['light']), 'rb') as f:\n",
    "    OR_mapping_catStr_to_RGB = pickle.load(f)[OR]\n",
    "\n",
    "import random\n",
    "# image_id = random.randint(0, len(split))\n",
    "# image_id = 3\n",
    "# pickle_path_ori = split[image_id]\n",
    "\n",
    "# pickle_id = random.randint(0, len(split))\n",
    "# pickle_id = 10\n",
    "# pickle_id = 26\n",
    "# pickle_id = 27\n",
    "\n",
    "pickle_id = 16 # blue room, sofa, window\n",
    "wall_idx, cell_i, cell_j = 2, 3, 3\n",
    "\n",
    "# pickle_id = 6\n",
    "# wall_idx, cell_i, cell_j = 4, 2, 4\n",
    "\n",
    "# pickle_id = 18 # classroom\n",
    "# wall_idx, cell_i, cell_j = 4, 3, 3\n",
    "\n",
    "# random\n",
    "# pickle_id = 25\n",
    "\n",
    "\n",
    "naming = split[pickle_id][2]\n",
    "\n",
    "# naming = 'main_xml1/scene0552_00/im_1.hdr'\n",
    "# naming = 'main_xml1/scene0552_00/im_1.hdr'\n",
    "# naming = 'mainDiffLight_xml1/scene0017_02/im_4.hdr'\n",
    "# naming = 'mainDiffMat_xml1/scene0695_03/im_26.hdr'\n",
    "# pickle_path_ori = '/data/ruizhu/OR-V3-OR45_total3D_train_test_data/%06d.pkl'%pickle_id\n",
    "meta_split = naming.split('/')[0]\n",
    "scene_name = naming.split('/')[1]\n",
    "withinsequence_id = int(naming.split('/')[2].split('.')[0].split('_')[1])\n",
    "# assert pickle_id==withinsequence_id\n",
    "\n",
    "train_test_data_path = '/data/ruizhu/OR-V4full-detachEmitterRERERE20210425-OR45_total3D_train_test_data'\n",
    "\n",
    "pickle_path_ori = '%s/%s/%s/%s'%(train_test_data_path, naming.split('/')[0], naming.split('/')[1], naming.split('/')[2].replace('im', 'layout_obj').replace('hdr', 'pkl'))\n",
    "\n",
    "\n",
    "grid_size = 8\n",
    "\n",
    "pickle_path = pickle_path_ori.replace('.pkl', '_reindexed.pkl')\n",
    "pickle_emitters_path = pickle_path_ori.replace('.pkl', '_emitters.pkl')\n",
    "pickle_emitters_assign_info_list_path = pickle_path_ori.replace('.pkl', '_emitters_assign_info_%dX%d_V4.pkl'%(grid_size, grid_size))\n",
    "\n",
    "print(pickle_path)\n",
    "\n",
    "# ======= read saved results from evaluation\n",
    "# results_folder = '20210427-142731--EVAL-20210427-011227'; tid=34000\n",
    "# results_folder = '20210427-041449-train_POD_emitterEst_lightAccuV3_bs2x4_GTBRDF-light-Light_FIXFIXFIXED2axis_overfitValMini_RE2'; tid=12000\n",
    "\n",
    "# EST\n",
    "# results_folder = '20210427-025334-train_POD_emitterEst_lightAccuV3_bs2x4_RuitrainedBRDF-light-Light_FIXFIXFIXED2axis'; tid=44000\n",
    "# GT\n",
    "# results_folder = '20210427-025239-train_POD_emitterEst_lightAccuV3_bs4x4_GT-BRDF-Light_FIXFIXFIXED2axis'; tid=24000\n",
    "\n",
    "# GT envmap input: 20210428-170647-train_POD_emitterEst_lightAccuV3_bs2x4_GTsampledEnvMap_FIXFIXFIXEDaxis\n",
    "results_folder = '20210429-214740--EVAL-20210428-170647'; tid=0\n",
    "\n",
    "layout_results_pickle_path = '/home/ruizhu/Documents/Projects/semanticInverse/Summary_vis/%s/results_layout_info_tid%d-%d.pickle'%(results_folder, tid, pickle_id)\n",
    "emitter_results_pickle_path = '/home/ruizhu/Documents/Projects/semanticInverse/Summary_vis/%s/results_cells_vis_info_list_tid%d-%d.pickle'%(results_folder, tid, pickle_id)\n",
    "\n",
    "with open(layout_results_pickle_path, 'rb') as f:\n",
    "    layout_pickle_dict = pickle.load(f)\n",
    "    print(layout_pickle_dict.keys())\n",
    "with open(emitter_results_pickle_path, 'rb') as f:\n",
    "    emitter_pickle_dict = pickle.load(f)\n",
    "    print(emitter_pickle_dict.keys())\n",
    "\n",
    "cells_vis_info_list = emitter_pickle_dict['cells_vis_info_list']\n",
    "cam_R_pred = layout_pickle_dict['pre_cam_R']\n",
    "pred_layout = layout_pickle_dict['pre_layout']\n",
    "emitter_cls_prob_PRED = emitter_pickle_dict['emitter_cls_prob_PRED']\n",
    "cell_info_grid_PRED = emitter_pickle_dict['cell_info_grid_PRED']\n",
    "\n",
    "results_emitter_input_pickle_path = '/home/ruizhu/Documents/Projects/semanticInverse/Summary_vis/%s/results_emitter_input_%d.pickle'%(results_folder, pickle_id)\n",
    "\n",
    "with open(results_emitter_input_pickle_path, 'rb') as f:\n",
    "    results_emitter_input_pickle_dict = pickle.load(f)\n",
    "    \n",
    "env_scale, hdr_scale = results_emitter_input_pickle_dict['env_scale'], results_emitter_input_pickle_dict['hdr_scale']\n",
    "print(env_scale, hdr_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rgb_img_path', 'depth_map', 'boxes', 'camera', 'layout', 'scene_name', 'withinsequence_id', 'meta_split', 'meta_name', 'sub_name', 'scene_pickle_file', 'cam_pickle_file', 'frame_pickle_file', 'reindex_info_dict'])\n",
      "dict_keys(['sequence_name', 'withinsequence_id', 'boxes', 'emitter_random_ids']) scene0385_01 32\n",
      "dict_keys(['emitter2wall_assign_info_list', 'emitters_obj_list', 'wall_grid_prob', 'cell_prob_mean', 'cell_prob', 'cell_count', 'cell_info_grid'])\n",
      "[[ 0.2981]\n",
      " [ 0.9515]\n",
      " [-0.076 ]]\n",
      "[[ 0.316 ]\n",
      " [ 0.9101]\n",
      " [-0.2683]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352a73f2c95c4b77ad9071d346ade11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[draw_projected_layout] Returned.\n",
      "\u001b[43m\u001b[34m Detected for 32:lamp not in valid_class_ids of dataset: OR\u001b[0m\n",
      "\u001b[43m\u001b[34m Detected for 32:lamp not in valid_class_ids of dataset: OR\u001b[0m\n",
      "\u001b[43m\u001b[34m Detected for 31:window not in valid_class_ids of dataset: OR\u001b[0m\n",
      "[draw_projected_bdb3d] Returned.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb6e97f063e41df9baf57dd477cde1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1, 2), (2, 1, 3), (2, 1, 4), (2, 1, 5), (2, 2, 2), (2, 2, 3), (2, 2, 4), (2, 2, 5), (2, 3, 2), (2, 3, 3), (2, 3, 4), (2, 3, 5), (2, 4, 2), (2, 4, 3), (2, 4, 4), (2, 4, 5), (2, 5, 2), (2, 5, 3), (2, 5, 4), (2, 5, 5), (5, 2, 2), (5, 2, 3), (5, 2, 4), (5, 2, 5), (5, 3, 2), (5, 3, 3), (5, 3, 4), (5, 3, 5), (5, 4, 2), (5, 4, 3), (5, 4, 4), (5, 4, 5), (5, 5, 2), (5, 5, 3), (5, 5, 4), (5, 5, 5)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    sequence = pickle.load(f)\n",
    "print(sequence.keys())\n",
    "\n",
    "with open(pickle_emitters_path, 'rb') as f:\n",
    "    sequence_emitters = pickle.load(f)\n",
    "print(sequence_emitters.keys(), sequence_emitters['sequence_name'], sequence_emitters['withinsequence_id'])\n",
    "with open(pickle_emitters_assign_info_list_path, 'rb') as f:\n",
    "    sequence_emitter2wall_assign_info_dict = pickle.load(f)\n",
    "print(sequence_emitter2wall_assign_info_dict.keys())\n",
    "\n",
    "import pickle5 as pickle\n",
    "emitter_representation_type = '0ambient'\n",
    "emitters_prop_dict_representation_dict_path = pickle_path.replace('layout_obj', ('emitters_prop_dict_%s'%emitter_representation_type)).replace('_reindexed', '')\n",
    "with open(emitters_prop_dict_representation_dict_path, 'rb') as f:\n",
    "    emitters_prop_dict_representation_dict = pickle.load(f)\n",
    "\n",
    "# transform_to_total3d_coords_dict = {'transform_R': frame.transform_R, 'transform_t': frame.transform_t}\n",
    "transform_to_total3d_coords_dict_path = Path(train_test_data_path) / meta_split / scene_name / ('transform_to_total3d_coords_dict_%d.pkl'%withinsequence_id)\n",
    "import pickle5 as pickle\n",
    "with open(transform_to_total3d_coords_dict_path, 'rb') as f:\n",
    "    transform_to_total3d_coords_dict = pickle.load(f)\n",
    "    \n",
    "# RAW_data_path = '/newfoundland2/ruizhu/siggraphasia20dataset/layout_labels_V4full-detachEmitterRERERE20210420/'\n",
    "# emitter_dict_pickle_file = Path(RAW_data_path) / meta_split / scene_name / ('emitter_dict_%s_%d.pickle'%('0ambient', withinsequence_id))\n",
    "# with open(emitter_dict_pickle_file, \"rb\") as f:\n",
    "#     emitter_dict_RAW = pickle.load(f)\n",
    "\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "gt_boxes_list = [format_layout(x) for x in sequence['boxes']['bdb3D']]\n",
    "for x, class_id in zip(gt_boxes_list, sequence['boxes']['size_cls']):\n",
    "    x.update({'class_id': class_id})\n",
    "gt_boxes_dict = {}\n",
    "for key in list(gt_boxes_list[0].keys()):\n",
    "    gt_boxes_dict[key] = [x[key] for x in gt_boxes_list]\n",
    "    \n",
    "gt_layout = sequence['layout']['bdb3D']\n",
    "\n",
    "from utils.utils_total3D.data_config import Dataset_Config\n",
    "from utils.utils_total3D.utils_OR_layout import to_dict_tensor\n",
    "\n",
    "from utils.utils_total3D.utils_OR_cam import get_rotation_matrix_gt\n",
    "\n",
    "OR = 'OR45'\n",
    "dataset_config = Dataset_Config(dataset, OR=OR, version='V3', paths={'total3D_lists_path': '../train/data/openrooms/list_OR_V4full', 'layout_emitter_path': '/data/ruizhu/OR-V4full-OR45_total3D_train_test_data'})\n",
    "bins_tensor = to_dict_tensor(dataset_config.bins, if_cuda=False)\n",
    "cam_R_gt = get_rotation_matrix_gt(bins_tensor,\n",
    "                                  torch.zeros([1]).long()+sequence['camera']['pitch_cls'], torch.zeros([1])+sequence['camera']['pitch_reg'],\n",
    "                                  torch.zeros([1]).long()+sequence['camera']['roll_cls'], torch.zeros([1])+sequence['camera']['roll_reg']).squeeze().numpy()\n",
    "\n",
    "# ======== emitters_list\n",
    "emitters_obj_list = []\n",
    "for x in range(sequence_emitters['boxes']['bdb3D'].shape[0]):\n",
    "    obj_dict_new = {'obj_box_3d': sequence_emitters['boxes']['bdb3D_emitter_part'][x], \\\n",
    "                    'random_id': sequence_emitters['boxes']['random_id'][x], \\\n",
    "                    'emitter_prop': sequence_emitters['boxes']['emitter_prop'][x], \\\n",
    "                    'bdb3D_emitter_part': sequence_emitters['boxes']['bdb3D_emitter_part'][x], \\\n",
    "                    'cat_id': sequence_emitters['boxes']['size_cls'][x], \\\n",
    "                    'cat_name': classes[sequence_emitters['boxes']['size_cls'][x]], 'cat_color': RGB_to_01(OR_mapping_catInt_to_RGB[sequence_emitters['boxes']['size_cls'][x]])}\n",
    "    obj_random_id = sequence_emitters['boxes']['random_id'][x]\n",
    "    emitter_prop_total3d = emitters_prop_dict_representation_dict[obj_random_id]['emitter_prop_total3d']\n",
    "    if sequence_emitters['boxes']['emitter_prop'][x]['obj_type'] == 'window':\n",
    "        light_center_world_total3d = emitter_prop_total3d['light_center_world_total3d'].reshape(3, 1)\n",
    "        light_axis_world_total3d = emitter_prop_total3d['light_axis_world_total3d'].reshape(3, 1)\n",
    "        print(light_axis_world_total3d)\n",
    "    else:\n",
    "        light_center_world_total3d = np.zeros((3, 1), dtype=np.float32)\n",
    "        light_axis_world_total3d = np.zeros((3, 1), dtype=np.float32)\n",
    "    obj_dict_new['light_world_total3d_centeraxis'] = [light_center_world_total3d, light_axis_world_total3d]\n",
    "    \n",
    "    obj_dict_new['emitter_prop'].update({'emitter_rgb_float': emitter_prop_total3d['intensity']})\n",
    "\n",
    "    emitters_obj_list.append(obj_dict_new)\n",
    "    \n",
    "emitter2wall_assign_info_list = sequence_emitter2wall_assign_info_dict['emitter2wall_assign_info_list']\n",
    "cell_info_grid_GT_includeempty = sequence_emitter2wall_assign_info_dict['cell_info_grid']\n",
    "cell_info_grid_GT = []\n",
    "for wall_idxx in range(6):\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            cell_info = cell_info_grid_GT_includeempty[wall_idxx * grid_size**2 + i * grid_size + j]\n",
    "            if cell_info['obj_type'] is None:\n",
    "                continue\n",
    "            cell_info['wallidx_i_j'] = (wall_idxx, i, j)\n",
    "            cell_info_grid_GT.append(cell_info)\n",
    "                \n",
    "            obj_random_id = cell_info['emitter_info']['random_id']\n",
    "            emitter_prop_total3d = emitters_prop_dict_representation_dict[obj_random_id]['emitter_prop_total3d']\n",
    "\n",
    "\n",
    "#             cell_intensity = np.array([emitter_prop_total3d['intensity_scale255'] * x * 255.for x in emitter_prop_total3d['intensity_scaled01']]) # intensity_scaled: [0., 1.]\n",
    "            cell_intensity = np.array(emitter_prop_total3d['intensity']) * env_scale * hdr_scale\n",
    "            cell_info['emitter_info']['intensity_scalelog'] = np.log(np.clip(np.linalg.norm(cell_intensity.flatten()) + 1., 1., np.inf))\n",
    "            cell_info['emitter_info']['intensity'] = [x * env_scale * hdr_scale for x in emitter_prop_total3d['intensity']]\n",
    "            intensity_scale255 = max(cell_info['emitter_info']['intensity']) / 255.\n",
    "            intensity_scaled01 = [np.clip(x / (intensity_scale255+1e-5) / 255., 0., 1.) for x in cell_info['emitter_info']['intensity']]\n",
    "            cell_info['emitter_info']['intensity_scaled01'] = intensity_scaled01\n",
    "\n",
    "            # other representation-specific params\n",
    "            if cell_info['obj_type'] == 'window':\n",
    "                cell_info['emitter_info']['lamb'] = emitter_prop_total3d['lamb']\n",
    "                cell_info['emitter_info']['light_dir_abs'] = emitter_prop_total3d['light_axis_world_total3d'].reshape(3,)\n",
    "                if emitter_representation_type in ['1ambient']:\n",
    "                    cell_info['emitter_info']['ambient'] = emitter_prop_total3d['ambient']\n",
    "                if emitter_representation_type in ['2ambient']:\n",
    "                    cell_info['emitter_info']['ambientL'] = emitter_prop_total3d['ambientL']\n",
    "                    cell_info['emitter_info']['ambientR'] = emitter_prop_total3d['ambientR']\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax_2d = plt.gca()\n",
    "\n",
    "grid_prob = sequence_emitter2wall_assign_info_dict['wall_grid_prob'].reshape(6, -1)\n",
    "import imageio\n",
    "rgb_img = imageio.imread(sequence['rgb_img_path'])\n",
    "\n",
    "scene_box = Box(rgb_img, None, sequence['camera']['K'], cam_R_gt, cam_R_pred, gt_layout, gt_layout, gt_boxes_dict, None, 'GT', None, dataset=dataset, OR='OR45', \\\n",
    "                emitters_obj_list=emitters_obj_list, emitter2wall_assign_info_list=emitter2wall_assign_info_list, \\\n",
    "                emitter_cls_prob_PRED=emitter_cls_prob_PRED, emitter_cls_prob_GT=grid_prob, cell_info_grid_GT=cell_info_grid_GT, cell_info_grid_PRED=cell_info_grid_PRED, \\\n",
    "                grid_size=grid_size, \\\n",
    "                paths={'color_file': '../train/data/openrooms/total3D_colors/OR4X_mapping_catInt_to_RGB_light.pkl'})\n",
    "if_use_plt=True\n",
    "img_map, _ = scene_box.draw_projected_layout('GT', return_plt=True, if_save=False, save_path='', if_use_plt=if_use_plt, fig_or_ax=ax_2d)\n",
    "img_map2 = scene_box.draw_projected_bdb3d('GT', return_plt=True, if_save=False, save_path='', if_use_plt=if_use_plt, fig_or_ax=ax_2d)\n",
    "# plt.show()\n",
    "\n",
    "fig_3d, ax_3ds_scene = scene_box.draw_3D_scene_plt('both', if_show_objs=False, hide_random_id=False, if_print_log=False)\n",
    "# ax_3d = ax_3ds[0]\n",
    "# ax_3ds_scene[0].view_init(elev=-46, azim=86)\n",
    "\n",
    "# %matplotlib widget\n",
    "# sys.path.insert(0, '/home/ruizhu/Documents/Projects/semanticInverse/train/SimpleLayout')\n",
    "# depth_combined, mask_conflict = scene_box.draw_projected_depth('GT', return_plt=True, if_save=False, save_path='', if_vis=True)\n",
    "\n",
    "wall_cell_idxes = []\n",
    "for x in cell_info_grid_GT:\n",
    "    if x['obj_type'] == 'window':\n",
    "        wall_cell_idxes.append(x['wallidx_i_j'])\n",
    "print(wall_cell_idxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff project emitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9291,  0.3699, -0.0001],\n",
       "       [-0.3699,  0.9291, -0.0002],\n",
       "       [-0.    ,  0.0002,  1.    ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_R_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[577.8708,   0.    , 320.    ],\n",
       "       [  0.    , 577.8708, 240.    ],\n",
       "       [  0.    ,   0.    ,   1.    ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence['camera']['K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.262 ,  1.3808,  1.47  ],\n",
       "       [ 2.9459,  1.3808, -2.4044],\n",
       "       [-1.1432,  1.3808, -1.0155],\n",
       "       [ 0.1729,  1.3808,  2.859 ],\n",
       "       [ 4.262 , -1.6192,  1.47  ],\n",
       "       [ 2.9459, -1.6192, -2.4044],\n",
       "       [-1.1432, -1.6192, -1.0155],\n",
       "       [ 0.1729, -1.6192,  2.859 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9291,  0.3699, -0.0001],\n",
       "       [-0.3699,  0.9291, -0.0002],\n",
       "       [-0.    ,  0.0002,  1.    ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_R_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_K_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b70e0b4417e4438a239a5699796daa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SimpleLayout.utils_SL_torch import SimpleSceneTorch\n",
    "\n",
    "cam_K = sequence['camera']['K'].astype(np.float32)\n",
    "im_width = 320\n",
    "im_height = 240\n",
    "cam_K_ratio = cam_K[0][2] / (im_width/2.)\n",
    "cam_K = cam_K / cam_K_ratio\n",
    "\n",
    "bdb_sample = torch.from_numpy(gt_layout).cuda().float()\n",
    "\n",
    "cam_dict = {'origin': torch.tensor([0., 0., 0.]).cuda(), 'cam_axes': torch.from_numpy(cam_R_gt.T).cuda(), \\\n",
    "            'f_x': torch.tensor(cam_K[0][0]).cuda(), 'f_y': torch.tensor(cam_K[1][1]).cuda(), 'width': int(im_width), 'height': int(im_height)}\n",
    "simpleSceneTorch = SimpleSceneTorch(cam_dict, bdb_sample)\n",
    "edges_front_list, face_edges_list, face_verts_list = simpleSceneTorch.get_edges_front(ax_3d=None, if_vis=False)\n",
    "mask_combined, mask_list, mask_conflict = simpleSceneTorch.poly_to_masks(face_verts_list)\n",
    "\n",
    "invd_list = simpleSceneTorch.param_planes()\n",
    "\n",
    "%matplotlib widget\n",
    "ax_2d = simpleSceneTorch.vis_2d_bbox_proj(bdb_sample.detach().cpu().numpy(), edge_list=[x[0] for x in edges_front_list], if_show=True)\n",
    "simpleSceneTorch.vis_mask_combined(mask_combined.cpu().numpy(), ax_2d=ax_2d)\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 4))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(depth_combined.detach().cpu().numpy(), cmap='jet')\n",
    "# plt.colorbar()\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(mask_conflict, cmap='jet')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:semanticInverse] *",
   "language": "python",
   "name": "conda-env-semanticInverse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
